{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/sidsanc/CMPE297-SpecialTopics/blob/main/Assignment2/Transformers%20and%20finetuning%20with%20LLMs/NanoGPT_JAX.ipynb","timestamp":1698126970539}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["## Importing Libraries and connecting Google Drive"],"metadata":{"id":"qv5Gv2OA5W1A"}},{"cell_type":"code","source":["!pip install jax jaxlib flax optax"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TxImIlJYSYH-","outputId":"0bc51a6a-a1dc-43d0-adb1-0c6882fa886d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.3.25)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.3.25)\n","Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.6.4)\n","Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (0.1.7)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from jax) (1.23.5)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n","Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax) (1.11.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from jax) (4.5.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from flax) (3.7.1)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.0.7)\n","Requirement already satisfied: orbax in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.2)\n","Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.45)\n","Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.6.0)\n","Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0.1)\n","Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax) (1.4.0)\n","Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax) (0.1.6)\n","Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax) (0.1.8)\n","Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax) (0.12.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.16.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax) (0.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax) (4.43.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax) (2.8.2)\n","Requirement already satisfied: cached_property in /usr/local/lib/python3.10/dist-packages (from orbax->flax) (1.5.2)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from orbax->flax) (6.1.0)\n","Requirement already satisfied: etils in /usr/local/lib/python3.10/dist-packages (from orbax->flax) (1.5.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->flax) (1.16.0)\n"]}]},{"cell_type":"code","source":["import jax\n","import jax.numpy as jnp\n","from jax import random, grad, jit, vmap, pmap\n","import flax\n","import flax.linen as nn\n","import optax\n","import numpy as np"],"metadata":{"id":"3yY-iywMHSKo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"metadata":{"id":"M9J0baV-tJSv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFX8NjVlSAVE"},"outputs":[],"source":["from google.colab import drive"]},{"cell_type":"code","source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"metadata":{"id":"I-b5d-crthCD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rng_key = jax.random.PRNGKey(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_arPpcqabn6","outputId":"2d9a6764-e268-478d-e9b1-7cefcca31ee5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"]}]},{"cell_type":"code","source":["# Download a file based on its file ID (the long string in the shareable link of a file in Google Drive)\n","file_id = '1uZiUwBQGpCcr2G9s1mXdwvNYnttTdOIU'\n","downloaded = drive.CreateFile({'id': file_id})\n","downloaded.GetContentFile('theSecretBook.txt')"],"metadata":{"id":"E9ER0U8stGwo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_file_path = '/content/theSecretBook.txt'"],"metadata":{"id":"0O3DBOYWajmH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hyperparameters\n","batch_size = 16\n","block_size = 32\n","max_iters = 2500\n","eval_interval = 200\n","learning_rate = 1e-3\n","eval_iters = 100\n","n_embd = 64\n","n_head = 4\n","n_layer = 8\n","# ------------"],"metadata":{"id":"2HkgSpoUpBZV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dataset Loading"],"metadata":{"id":"KG7ARreGIXFY"}},{"cell_type":"code","source":["class Dataset:\n","  def __init__(self):\n","    self.vocab_size = 0\n","    self.train_data = jnp.array([], dtype=jnp.int32)\n","    self.val_data = jnp.array([], dtype=jnp.int32)\n","\n","  def read_dataset(self):\n","    with open(input_file_path, 'r', encoding='utf-8') as f:\n","        self.data = f.read()\n","\n","  def prepare_dataset(self):\n","    self.read_dataset()\n","\n","    chars = sorted(list(set(self.data)))\n","    self.vocab_size = len(chars)\n","    char_to_int = {ch: i for i, ch in enumerate(chars)}\n","    int_to_char = {i: ch for i, ch in enumerate(chars)}\n","    self.encode = lambda s: [char_to_int[c] for c in s]\n","    self.decode = lambda l: ''.join([int_to_char[i] for i in l])\n","\n","  def data_split(self):\n","    self.prepare_dataset()\n","\n","    data_tensor = jnp.array(self.encode(self.data), dtype=jnp.int32)\n","    n = int(0.8 * len(data_tensor))\n","    self.train_data = data_tensor[:n]\n","    self.val_data = data_tensor[n:]\n","\n","  def get_batch(self, split):\n","    self.data_split()\n","\n","    data = self.train_data if split == 'train' else self.val_data\n","    ix = random.randint(rng_key, (batch_size,), 0, len(data) - block_size)\n","    x = jnp.stack([data[i:i+block_size] for i in ix])\n","    y = jnp.stack([data[i+1:i+block_size+1] for i in ix])\n","    return x, y"],"metadata":{"id":"z_tU3JwNIXTl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loss Function"],"metadata":{"id":"n2w2GWsQIifZ"}},{"cell_type":"code","source":["class Loss:\n","  def estimate_loss(self):\n","    out = {}\n","    for split in ['train', 'val']:\n","        losses = []\n","        for k in range(eval_iters):\n","            X, Y = dataObj.get_batch(split)\n","            logits, loss = model(X, Y)\n","            losses.append(loss)\n","        out[split] = jnp.mean(jnp.array(losses))\n","    return out\n","\n","lossObj = Loss()"],"metadata":{"id":"xlQjs1bPIivK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"wA_CEGWTOF-v"}},{"cell_type":"code","source":["class Head(nn.Module):\n","    head_size: int\n","\n","    def setup(self):\n","        self.key = nn.Dense(self.head_size, use_bias=False, kernel_init=nn.initializers.xavier_uniform())\n","        self.query = nn.Dense(self.head_size, use_bias=False, kernel_init=nn.initializers.xavier_uniform())\n","        self.value = nn.Dense(self.head_size, use_bias=False, kernel_init=nn.initializers.xavier_uniform())\n","        self.tril = jnp.tril(jnp.ones((block_size, block_size)))\n","\n","    def __call__(self, x):\n","        B, T, C = x.shape\n","        k = self.key(x)\n","        q = self.query(x)\n","        w = jnp.matmul(q, jnp.transpose(k, (0, 2, 1))) * C ** -0.5\n","        w = jnp.where(self.tril[:T, :T] == 0, float('-inf'), w)\n","        w = nn.softmax(w, axis=-1)\n","\n","        v = self.value(x)\n","        out = jnp.matmul(w, v)\n","\n","        return out"],"metadata":{"id":"5Go5buCTOGPL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"LmguAzAyOuyQ"}},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    n_head: int\n","    head_size: int\n","\n","    def setup(self):\n","        self.heads = [Head(self.head_size) for _ in range(self.n_head)]\n","        self.proj = nn.Dense(n_embd)\n","\n","    def __call__(self, x):\n","        out = jnp.concatenate([h(x) for h in self.heads], axis=-1)\n","        return self.proj(out)"],"metadata":{"id":"CIT159tHOvu1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"q7Idzo2kPE1f"}},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","  def setup(self):\n","    self.net = nn.Sequential([\n","        nn.Dense(4 * n_embd),\n","        nn.relu,\n","        nn.Dense(n_embd)\n","    ])\n","\n","  def __call__(self, x):\n","    return self.net(x)"],"metadata":{"id":"azhsW5DMO_Vc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","    def setup(self):\n","        head_size = n_embd // n_head\n","        self.sa = MultiHeadAttention(n_head=n_head, head_size=head_size)\n","        self.ffwd = FeedForward()\n","        self.ln1 = nn.LayerNorm(epsilon=1e-6)\n","        self.ln2 = nn.LayerNorm(epsilon=1e-6)\n","\n","    def __call__(self, x):\n","        x = x + self.sa(x)\n","        x = x + self.ffwd(x)\n","        return x"],"metadata":{"id":"mWqL_klpPF97"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TokenEmbedding(nn.Module):\n","    @nn.compact\n","    def __call__(self, idx):\n","        return nn.Dense(n_embd, use_bias=False)(jax.nn.one_hot(idx, dataObj.vocab_size))\n","\n","class PositionEmbedding(nn.Module):\n","    def setup(self):\n","        self.T = None  # Initialize T as None\n","\n","    def set_T(self, T):\n","        self.T = T  # Set T dynamically\n","\n","    @nn.compact\n","    def __call__(self, idx):\n","        assert self.T is not None, \"T must be set using set_T() before calling PositionEmbedding\"\n","        return nn.Dense(n_embd, use_bias=False)(jax.nn.one_hot(jnp.arange(self.T), block_size))\n","\n","class NanoGPT(nn.Module):\n","    def setup(self):\n","        self.blocks = [TransformerBlock() for _ in range(n_layer)]\n","        self.ln_f = nn.LayerNorm(epsilon=1e-6)\n","        self.lm_head = nn.Dense(dataObj.vocab_size, kernel_init=nn.initializers.xavier_uniform())\n","\n","        # Initialize submodules within setup\n","        self.token_embedding = TokenEmbedding()\n","        self.position_embedding = PositionEmbedding()\n","\n","    def __call__(self, idx, targets=None):\n","        B, T = idx.shape\n","\n","        tok_emb = self.token_embedding(idx)\n","        self.position_embedding.set_T(T)  # Set T dynamically\n","        pos_emb = self.position_embedding(jnp.arange(T))\n","\n","        x = tok_emb + pos_emb\n","        for block in self.blocks:\n","            x = block(x)\n","        x = self.ln_f(x)\n","        logits = self.lm_head(x)\n","\n","        loss = None\n","        if targets is not None:\n","            loss = jnp.mean(jax.nn.softmax_cross_entropy(logits, jax.nn.one_hot(targets, dataObj.vocab_size)))\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens, key):\n","        for _ in range(max_new_tokens):\n","            idx_cond = idx[:, -block_size:]\n","            logits, _ = self(idx_cond)\n","            logits = logits[:, -1, :]\n","            probs = nn.softmax(logits)\n","            idx_next = random.categorical(key, logits)\n","            idx = jnp.concatenate([idx, idx_next[:, None]], axis=1)\n","        return idx"],"metadata":{"id":"TnMP6DWZPXKe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generateNext():\n","  key = random.PRNGKey(0)\n","  context = jnp.zeros((1, 1), dtype=jnp.int32)\n","  generated_seq = model.generate(context, max_new_tokens=2000, key=key)\n","  print(dataObj.decode(generated_seq[0].tolist()))\n"],"metadata":{"id":"1D7OT3CcPprq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","  dataObj = Dataset()\n","  dataObj.read_dataset()\n","  dataObj.prepare_dataset()\n","\n","  model = NanoGPT()\n","  params = model.init(rng_key, jnp.zeros((1, block_size), dtype=jnp.int32))\n","\n","  optimizer = optax.adam(learning_rate=learning_rate)\n","  state = optimizer.init(params)\n","\n","  @jit\n","  def update(params, xb, yb, state):\n","      logits, loss = model.apply({'params': params}, xb, yb)\n","      grads = jax.grad(loss)(params)\n","      updates, new_state = optimizer.update(grads, state)\n","      new_params = optax.apply_updates(params, updates)\n","      return new_params, loss, new_state\n","\n","  for iter in range(max_iters):\n","      if iter % eval_interval == 0 or iter == max_iters - 1:\n","          losses = lossObj.estimate_loss()\n","          print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","      xb, yb = dataObj.get_batch('train')\n","      params, loss, state = update(params, xb, yb, state)"],"metadata":{"id":"l8VmVPTXPr4v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generateNext()"],"metadata":{"id":"XZuXM-glTWk9"},"execution_count":null,"outputs":[]}]}