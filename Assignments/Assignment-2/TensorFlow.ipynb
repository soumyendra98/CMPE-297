{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries and connecting Google Drive"
      ],
      "metadata": {
        "id": "qv5Gv2OA5W1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "metadata": {
        "id": "M9J0baV-tJSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFX8NjVlSAVE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "I-b5d-crthCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a file based on its file ID (the long string in the shareable link of a file in Google Drive)\n",
        "file_id = '1uZiUwBQGpCcr2G9s1mXdwvNYnttTdOIU'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('theSecretBook.txt')\n",
        "input_file_path = '/content/theSecretBook.txt'"
      ],
      "metadata": {
        "id": "E9ER0U8stGwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 1000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 10\n",
        "n_embd = 64\n",
        "n_head = 8\n",
        "n_layer = 8\n",
        "dropout = 0.0\n",
        "# ------------"
      ],
      "metadata": {
        "id": "2HkgSpoUpBZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Loading"
      ],
      "metadata": {
        "id": "rYHjkoDT52Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "  def __init__(self):\n",
        "    self.vocab_size = 0\n",
        "    self.train_data = tf.constant([], dtype=tf.int32)\n",
        "    self.val_data = tf.constant([], dtype=tf.int32)\n",
        "\n",
        "  def read_dataset(self):\n",
        "    with open(input_file_path, 'r', encoding='utf-8') as f:\n",
        "        self.data = f.read()\n",
        "\n",
        "  def prepare_dataset(self):\n",
        "    chars = sorted(list(set(self.data)))\n",
        "    self.vocab_size = len(chars)\n",
        "    char_to_int = { ch:i for i,ch in enumerate(chars) }\n",
        "    int_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "    self.encode = lambda s: [char_to_int[c] for c in s]\n",
        "    self.decode = lambda l: ''.join([int_to_char[i] for i in l])\n",
        "\n",
        "  def data_split(self):\n",
        "    data_tensor = tf.convert_to_tensor(self.encode(self.data), dtype=tf.int32)\n",
        "    n = int(0.8*len(data_tensor))\n",
        "    self.train_data = data_tensor[:n]\n",
        "    self.val_data = data_tensor[n:]\n",
        "\n",
        "  def get_batch(self, split):\n",
        "    data = self.train_data if split == 'train' else self.val_data\n",
        "    data_length = tf.shape(data)[0]\n",
        "    ix = tf.random.uniform([batch_size], minval=0, maxval=data_length - block_size, dtype=tf.int32)\n",
        "    start_indices = tf.expand_dims(ix, -1)\n",
        "    range_indices = tf.range(block_size, dtype=tf.int32)\n",
        "    indices = start_indices + range_indices\n",
        "\n",
        "    x = tf.gather(data, indices)\n",
        "\n",
        "    y_indices = start_indices + 1 + range_indices\n",
        "    y = tf.gather(data, y_indices)\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "rrd7yijpOcIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataObj = Dataset()\n",
        "dataObj.read_dataset()\n",
        "dataObj.prepare_dataset()\n",
        "dataObj.data_split()"
      ],
      "metadata": {
        "id": "a2Ic1HsCymJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function"
      ],
      "metadata": {
        "id": "DGhcv6VK56Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss:\n",
        "  def estimate_loss(self):\n",
        "    out = {}\n",
        "    for split in ['train', 'val']:\n",
        "      total_loss = tf.zeros([])\n",
        "      for k in range(eval_iters):\n",
        "          X, Y = dataObj.get_batch(split)\n",
        "          _, loss = model(X, Y)\n",
        "          total_loss += loss\n",
        "      out[split] = total_loss / eval_iters\n",
        "    return out\n",
        "\n",
        "lossObj = Loss()"
      ],
      "metadata": {
        "id": "f5jMGt9Gy38H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lossObj = Loss()"
      ],
      "metadata": {
        "id": "X3kL5IcyzDE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Head"
      ],
      "metadata": {
        "id": "CjtExP_l59Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(tf.keras.layers.Layer):\n",
        "  def __init__(self, head_size, n_embd, block_size):\n",
        "    super(Head, self).__init__()\n",
        "    self.key = tf.keras.layers.Dense(head_size, use_bias=False, input_shape=(n_embd,))\n",
        "    self.query = tf.keras.layers.Dense(head_size, use_bias=False, input_shape=(n_embd,))\n",
        "    self.value = tf.keras.layers.Dense(head_size, use_bias=False, input_shape=(n_embd,))\n",
        "    self.tril = tf.linalg.band_part(tf.ones((block_size, block_size)), -1, 0)\n",
        "\n",
        "  def call(self, x):\n",
        "    B, T, C = x.shape\n",
        "    k = self.key(x)\n",
        "    q = self.query(x)\n",
        "    w = tf.matmul(q, k, transpose_b=True) * C**-0.5\n",
        "    w = tf.where(self.tril[:T, :T] == 0, float('-inf'), w)\n",
        "    w = tf.nn.softmax(w, axis=-1)\n",
        "\n",
        "    v = self.value(x)\n",
        "    out = tf.matmul(w, v)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "bTVi1D-uSKQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multihead Attention"
      ],
      "metadata": {
        "id": "FIAZ1Ckm6Ack"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_heads, head_size, n_embd, block_size):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.heads = [Head(head_size, n_embd, block_size) for _ in range(num_heads)]\n",
        "    self.proj = tf.keras.layers.Dense(n_embd)\n",
        "\n",
        "  def call(self, x):\n",
        "    out = tf.concat([h(x) for h in self.heads], axis=-1)\n",
        "    return self.proj(out)"
      ],
      "metadata": {
        "id": "_D0dOJhEzRqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FeedForward Network"
      ],
      "metadata": {
        "id": "WtiFxvQh6FBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, n_embd):\n",
        "    super(FeedForward, self).__init__()\n",
        "    self.net = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(4 * n_embd),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.Dense(n_embd)\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "HbNFhRoXzWBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, n_embd, n_head, block_size):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    head_size = n_embd // n_head\n",
        "    self.sa = MultiHeadAttention(n_head, head_size, n_embd, block_size)\n",
        "    self.ffwd = FeedForward(n_embd)\n",
        "    self.ln1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.ln2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "aV8Trt7HUVkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NanoGPT(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(NanoGPT, self).__init__()\n",
        "    self.token_embedding_table = tf.keras.layers.Embedding(dataObj.vocab_size, n_embd)\n",
        "    self.position_embedding_table = tf.keras.layers.Embedding(block_size, n_embd)\n",
        "    self.blocks = tf.keras.Sequential([TransformerBlock(n_embd, n_head, block_size) for _ in range(n_layer)])\n",
        "    self.ln_f = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.lm_head = tf.keras.layers.Dense(dataObj.vocab_size)\n",
        "\n",
        "  def call(self, idx, targets=None, training=False):\n",
        "    shape = tf.shape(idx)\n",
        "    B = shape[0]\n",
        "    T = shape[1]\n",
        "    tok_emb = self.token_embedding_table(idx)\n",
        "    pos_emb = self.position_embedding_table(tf.range(T))\n",
        "    x = tok_emb + pos_emb\n",
        "    x = self.blocks(x)\n",
        "    x = self.ln_f(x)\n",
        "    logits = self.lm_head(x)\n",
        "\n",
        "    if targets is None:\n",
        "        loss = None\n",
        "    else:\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(targets, logits, from_logits=True)\n",
        "        loss = tf.reduce_mean(loss)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens, batch_size=4):\n",
        "    for _ in range(max_new_tokens):\n",
        "      idx_cond = idx[:, -block_size:]\n",
        "      logits, _ = self(idx_cond)\n",
        "      logits = logits[:, -1, :]\n",
        "\n",
        "      idx_next = tf.random.categorical(logits, num_samples=batch_size, dtype=tf.int32)\n",
        "\n",
        "      idx = tf.concat([idx, idx_next], axis=1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "6wlMV8JYUjiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateNext():\n",
        "  context = tf.zeros((1, 1), dtype=tf.int32)\n",
        "  generated_seq = model.generate(context, max_new_tokens=500)\n",
        "  print(dataObj.decode(generated_seq[0].numpy()))"
      ],
      "metadata": {
        "id": "dyCbV9XLWH5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TozLG9XW53XR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9e10da-476d-4223-d7a4-6cd1ac04a1c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration =  0\n",
            "step 0: train loss 4.9351, val loss 4.9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7d79ce3a77f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7d79ce3a77f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration =  1\n",
            "Iteration =  2\n",
            "Iteration =  3\n",
            "Iteration =  4\n",
            "Iteration =  5\n",
            "Iteration =  6\n",
            "Iteration =  7\n",
            "Iteration =  8\n",
            "Iteration =  9\n",
            "Iteration =  10\n",
            "Iteration =  11\n",
            "Iteration =  12\n",
            "Iteration =  13\n",
            "Iteration =  14\n",
            "Iteration =  15\n",
            "Iteration =  16\n",
            "Iteration =  17\n",
            "Iteration =  18\n",
            "Iteration =  19\n",
            "Iteration =  20\n",
            "Iteration =  21\n",
            "Iteration =  22\n",
            "Iteration =  23\n",
            "Iteration =  24\n",
            "Iteration =  25\n",
            "Iteration =  26\n",
            "Iteration =  27\n",
            "Iteration =  28\n",
            "Iteration =  29\n",
            "Iteration =  30\n",
            "Iteration =  31\n",
            "Iteration =  32\n",
            "Iteration =  33\n",
            "Iteration =  34\n",
            "Iteration =  35\n",
            "Iteration =  36\n",
            "Iteration =  37\n",
            "Iteration =  38\n",
            "Iteration =  39\n",
            "Iteration =  40\n",
            "Iteration =  41\n",
            "Iteration =  42\n",
            "Iteration =  43\n",
            "Iteration =  44\n",
            "Iteration =  45\n",
            "Iteration =  46\n",
            "Iteration =  47\n",
            "Iteration =  48\n",
            "Iteration =  49\n",
            "Iteration =  50\n",
            "Iteration =  51\n",
            "Iteration =  52\n",
            "Iteration =  53\n",
            "Iteration =  54\n",
            "Iteration =  55\n",
            "Iteration =  56\n",
            "Iteration =  57\n",
            "Iteration =  58\n",
            "Iteration =  59\n",
            "Iteration =  60\n",
            "Iteration =  61\n",
            "Iteration =  62\n",
            "Iteration =  63\n",
            "Iteration =  64\n",
            "Iteration =  65\n",
            "Iteration =  66\n",
            "Iteration =  67\n",
            "Iteration =  68\n",
            "Iteration =  69\n",
            "Iteration =  70\n",
            "Iteration =  71\n",
            "Iteration =  72\n",
            "Iteration =  73\n",
            "Iteration =  74\n",
            "Iteration =  75\n",
            "Iteration =  76\n",
            "Iteration =  77\n",
            "Iteration =  78\n",
            "Iteration =  79\n",
            "Iteration =  80\n",
            "Iteration =  81\n",
            "Iteration =  82\n",
            "Iteration =  83\n",
            "Iteration =  84\n",
            "Iteration =  85\n",
            "Iteration =  86\n",
            "Iteration =  87\n",
            "Iteration =  88\n",
            "Iteration =  89\n",
            "Iteration =  90\n",
            "Iteration =  91\n",
            "Iteration =  92\n",
            "Iteration =  93\n",
            "Iteration =  94\n",
            "Iteration =  95\n",
            "Iteration =  96\n",
            "Iteration =  97\n",
            "Iteration =  98\n",
            "Iteration =  99\n",
            "Iteration =  100\n",
            "step 100: train loss 2.6817, val loss 2.6694\n",
            "Iteration =  101\n",
            "Iteration =  102\n",
            "Iteration =  103\n",
            "Iteration =  104\n",
            "Iteration =  105\n",
            "Iteration =  106\n",
            "Iteration =  107\n",
            "Iteration =  108\n",
            "Iteration =  109\n",
            "Iteration =  110\n",
            "Iteration =  111\n",
            "Iteration =  112\n",
            "Iteration =  113\n",
            "Iteration =  114\n",
            "Iteration =  115\n",
            "Iteration =  116\n",
            "Iteration =  117\n",
            "Iteration =  118\n",
            "Iteration =  119\n",
            "Iteration =  120\n",
            "Iteration =  121\n",
            "Iteration =  122\n",
            "Iteration =  123\n",
            "Iteration =  124\n",
            "Iteration =  125\n",
            "Iteration =  126\n",
            "Iteration =  127\n",
            "Iteration =  128\n",
            "Iteration =  129\n",
            "Iteration =  130\n",
            "Iteration =  131\n",
            "Iteration =  132\n",
            "Iteration =  133\n",
            "Iteration =  134\n",
            "Iteration =  135\n",
            "Iteration =  136\n",
            "Iteration =  137\n",
            "Iteration =  138\n",
            "Iteration =  139\n",
            "Iteration =  140\n",
            "Iteration =  141\n",
            "Iteration =  142\n",
            "Iteration =  143\n",
            "Iteration =  144\n",
            "Iteration =  145\n",
            "Iteration =  146\n",
            "Iteration =  147\n",
            "Iteration =  148\n",
            "Iteration =  149\n",
            "Iteration =  150\n",
            "Iteration =  151\n",
            "Iteration =  152\n",
            "Iteration =  153\n",
            "Iteration =  154\n",
            "Iteration =  155\n",
            "Iteration =  156\n",
            "Iteration =  157\n",
            "Iteration =  158\n",
            "Iteration =  159\n",
            "Iteration =  160\n",
            "Iteration =  161\n",
            "Iteration =  162\n",
            "Iteration =  163\n",
            "Iteration =  164\n",
            "Iteration =  165\n",
            "Iteration =  166\n",
            "Iteration =  167\n",
            "Iteration =  168\n",
            "Iteration =  169\n",
            "Iteration =  170\n",
            "Iteration =  171\n",
            "Iteration =  172\n",
            "Iteration =  173\n",
            "Iteration =  174\n",
            "Iteration =  175\n",
            "Iteration =  176\n",
            "Iteration =  177\n",
            "Iteration =  178\n",
            "Iteration =  179\n",
            "Iteration =  180\n",
            "Iteration =  181\n",
            "Iteration =  182\n",
            "Iteration =  183\n",
            "Iteration =  184\n",
            "Iteration =  185\n",
            "Iteration =  186\n",
            "Iteration =  187\n",
            "Iteration =  188\n",
            "Iteration =  189\n",
            "Iteration =  190\n",
            "Iteration =  191\n",
            "Iteration =  192\n",
            "Iteration =  193\n",
            "Iteration =  194\n",
            "Iteration =  195\n",
            "Iteration =  196\n",
            "Iteration =  197\n",
            "Iteration =  198\n",
            "Iteration =  199\n",
            "Iteration =  200\n",
            "step 200: train loss 2.4229, val loss 2.4875\n",
            "Iteration =  201\n",
            "Iteration =  202\n",
            "Iteration =  203\n",
            "Iteration =  204\n",
            "Iteration =  205\n",
            "Iteration =  206\n",
            "Iteration =  207\n",
            "Iteration =  208\n",
            "Iteration =  209\n",
            "Iteration =  210\n",
            "Iteration =  211\n",
            "Iteration =  212\n",
            "Iteration =  213\n",
            "Iteration =  214\n",
            "Iteration =  215\n",
            "Iteration =  216\n",
            "Iteration =  217\n",
            "Iteration =  218\n",
            "Iteration =  219\n",
            "Iteration =  220\n",
            "Iteration =  221\n",
            "Iteration =  222\n",
            "Iteration =  223\n",
            "Iteration =  224\n",
            "Iteration =  225\n",
            "Iteration =  226\n",
            "Iteration =  227\n",
            "Iteration =  228\n",
            "Iteration =  229\n",
            "Iteration =  230\n",
            "Iteration =  231\n",
            "Iteration =  232\n",
            "Iteration =  233\n",
            "Iteration =  234\n",
            "Iteration =  235\n",
            "Iteration =  236\n",
            "Iteration =  237\n",
            "Iteration =  238\n",
            "Iteration =  239\n",
            "Iteration =  240\n",
            "Iteration =  241\n",
            "Iteration =  242\n",
            "Iteration =  243\n",
            "Iteration =  244\n",
            "Iteration =  245\n",
            "Iteration =  246\n",
            "Iteration =  247\n",
            "Iteration =  248\n",
            "Iteration =  249\n",
            "Iteration =  250\n",
            "Iteration =  251\n",
            "Iteration =  252\n",
            "Iteration =  253\n",
            "Iteration =  254\n",
            "Iteration =  255\n",
            "Iteration =  256\n",
            "Iteration =  257\n",
            "Iteration =  258\n",
            "Iteration =  259\n",
            "Iteration =  260\n",
            "Iteration =  261\n",
            "Iteration =  262\n",
            "Iteration =  263\n",
            "Iteration =  264\n",
            "Iteration =  265\n",
            "Iteration =  266\n",
            "Iteration =  267\n",
            "Iteration =  268\n",
            "Iteration =  269\n",
            "Iteration =  270\n",
            "Iteration =  271\n",
            "Iteration =  272\n",
            "Iteration =  273\n",
            "Iteration =  274\n",
            "Iteration =  275\n",
            "Iteration =  276\n",
            "Iteration =  277\n",
            "Iteration =  278\n",
            "Iteration =  279\n",
            "Iteration =  280\n",
            "Iteration =  281\n",
            "Iteration =  282\n",
            "Iteration =  283\n",
            "Iteration =  284\n",
            "Iteration =  285\n",
            "Iteration =  286\n",
            "Iteration =  287\n",
            "Iteration =  288\n",
            "Iteration =  289\n",
            "Iteration =  290\n",
            "Iteration =  291\n",
            "Iteration =  292\n",
            "Iteration =  293\n",
            "Iteration =  294\n",
            "Iteration =  295\n",
            "Iteration =  296\n",
            "Iteration =  297\n",
            "Iteration =  298\n",
            "Iteration =  299\n",
            "Iteration =  300\n",
            "step 300: train loss 2.3145, val loss 2.3788\n",
            "Iteration =  301\n",
            "Iteration =  302\n",
            "Iteration =  303\n",
            "Iteration =  304\n",
            "Iteration =  305\n",
            "Iteration =  306\n",
            "Iteration =  307\n",
            "Iteration =  308\n",
            "Iteration =  309\n",
            "Iteration =  310\n",
            "Iteration =  311\n",
            "Iteration =  312\n",
            "Iteration =  313\n",
            "Iteration =  314\n",
            "Iteration =  315\n",
            "Iteration =  316\n",
            "Iteration =  317\n",
            "Iteration =  318\n",
            "Iteration =  319\n",
            "Iteration =  320\n",
            "Iteration =  321\n",
            "Iteration =  322\n",
            "Iteration =  323\n",
            "Iteration =  324\n",
            "Iteration =  325\n",
            "Iteration =  326\n",
            "Iteration =  327\n",
            "Iteration =  328\n",
            "Iteration =  329\n",
            "Iteration =  330\n",
            "Iteration =  331\n",
            "Iteration =  332\n",
            "Iteration =  333\n",
            "Iteration =  334\n",
            "Iteration =  335\n",
            "Iteration =  336\n",
            "Iteration =  337\n",
            "Iteration =  338\n",
            "Iteration =  339\n",
            "Iteration =  340\n",
            "Iteration =  341\n",
            "Iteration =  342\n",
            "Iteration =  343\n",
            "Iteration =  344\n",
            "Iteration =  345\n",
            "Iteration =  346\n",
            "Iteration =  347\n",
            "Iteration =  348\n",
            "Iteration =  349\n",
            "Iteration =  350\n",
            "Iteration =  351\n",
            "Iteration =  352\n",
            "Iteration =  353\n",
            "Iteration =  354\n",
            "Iteration =  355\n",
            "Iteration =  356\n",
            "Iteration =  357\n",
            "Iteration =  358\n",
            "Iteration =  359\n",
            "Iteration =  360\n",
            "Iteration =  361\n",
            "Iteration =  362\n",
            "Iteration =  363\n",
            "Iteration =  364\n",
            "Iteration =  365\n",
            "Iteration =  366\n",
            "Iteration =  367\n",
            "Iteration =  368\n",
            "Iteration =  369\n",
            "Iteration =  370\n",
            "Iteration =  371\n",
            "Iteration =  372\n",
            "Iteration =  373\n",
            "Iteration =  374\n",
            "Iteration =  375\n",
            "Iteration =  376\n",
            "Iteration =  377\n",
            "Iteration =  378\n",
            "Iteration =  379\n",
            "Iteration =  380\n",
            "Iteration =  381\n",
            "Iteration =  382\n",
            "Iteration =  383\n",
            "Iteration =  384\n",
            "Iteration =  385\n",
            "Iteration =  386\n",
            "Iteration =  387\n",
            "Iteration =  388\n",
            "Iteration =  389\n",
            "Iteration =  390\n",
            "Iteration =  391\n",
            "Iteration =  392\n",
            "Iteration =  393\n",
            "Iteration =  394\n",
            "Iteration =  395\n",
            "Iteration =  396\n",
            "Iteration =  397\n",
            "Iteration =  398\n",
            "Iteration =  399\n",
            "Iteration =  400\n",
            "step 400: train loss 2.1977, val loss 2.3820\n",
            "Iteration =  401\n",
            "Iteration =  402\n",
            "Iteration =  403\n",
            "Iteration =  404\n",
            "Iteration =  405\n",
            "Iteration =  406\n",
            "Iteration =  407\n",
            "Iteration =  408\n",
            "Iteration =  409\n",
            "Iteration =  410\n",
            "Iteration =  411\n",
            "Iteration =  412\n",
            "Iteration =  413\n",
            "Iteration =  414\n",
            "Iteration =  415\n",
            "Iteration =  416\n",
            "Iteration =  417\n",
            "Iteration =  418\n",
            "Iteration =  419\n",
            "Iteration =  420\n",
            "Iteration =  421\n",
            "Iteration =  422\n",
            "Iteration =  423\n",
            "Iteration =  424\n",
            "Iteration =  425\n",
            "Iteration =  426\n",
            "Iteration =  427\n",
            "Iteration =  428\n",
            "Iteration =  429\n",
            "Iteration =  430\n",
            "Iteration =  431\n",
            "Iteration =  432\n",
            "Iteration =  433\n",
            "Iteration =  434\n",
            "Iteration =  435\n",
            "Iteration =  436\n",
            "Iteration =  437\n",
            "Iteration =  438\n",
            "Iteration =  439\n",
            "Iteration =  440\n",
            "Iteration =  441\n",
            "Iteration =  442\n",
            "Iteration =  443\n",
            "Iteration =  444\n",
            "Iteration =  445\n",
            "Iteration =  446\n",
            "Iteration =  447\n",
            "Iteration =  448\n",
            "Iteration =  449\n",
            "Iteration =  450\n",
            "Iteration =  451\n",
            "Iteration =  452\n",
            "Iteration =  453\n",
            "Iteration =  454\n",
            "Iteration =  455\n",
            "Iteration =  456\n",
            "Iteration =  457\n",
            "Iteration =  458\n",
            "Iteration =  459\n",
            "Iteration =  460\n",
            "Iteration =  461\n",
            "Iteration =  462\n",
            "Iteration =  463\n",
            "Iteration =  464\n",
            "Iteration =  465\n",
            "Iteration =  466\n",
            "Iteration =  467\n",
            "Iteration =  468\n",
            "Iteration =  469\n",
            "Iteration =  470\n",
            "Iteration =  471\n",
            "Iteration =  472\n",
            "Iteration =  473\n",
            "Iteration =  474\n",
            "Iteration =  475\n",
            "Iteration =  476\n",
            "Iteration =  477\n",
            "Iteration =  478\n",
            "Iteration =  479\n",
            "Iteration =  480\n",
            "Iteration =  481\n",
            "Iteration =  482\n",
            "Iteration =  483\n",
            "Iteration =  484\n",
            "Iteration =  485\n",
            "Iteration =  486\n",
            "Iteration =  487\n",
            "Iteration =  488\n",
            "Iteration =  489\n",
            "Iteration =  490\n",
            "Iteration =  491\n",
            "Iteration =  492\n",
            "Iteration =  493\n",
            "Iteration =  494\n",
            "Iteration =  495\n",
            "Iteration =  496\n",
            "Iteration =  497\n",
            "Iteration =  498\n",
            "Iteration =  499\n",
            "Iteration =  500\n",
            "step 500: train loss 2.0915, val loss 2.2598\n",
            "Iteration =  501\n",
            "Iteration =  502\n",
            "Iteration =  503\n",
            "Iteration =  504\n",
            "Iteration =  505\n",
            "Iteration =  506\n",
            "Iteration =  507\n",
            "Iteration =  508\n",
            "Iteration =  509\n",
            "Iteration =  510\n",
            "Iteration =  511\n",
            "Iteration =  512\n",
            "Iteration =  513\n",
            "Iteration =  514\n",
            "Iteration =  515\n",
            "Iteration =  516\n",
            "Iteration =  517\n",
            "Iteration =  518\n",
            "Iteration =  519\n",
            "Iteration =  520\n",
            "Iteration =  521\n",
            "Iteration =  522\n",
            "Iteration =  523\n",
            "Iteration =  524\n",
            "Iteration =  525\n",
            "Iteration =  526\n",
            "Iteration =  527\n",
            "Iteration =  528\n",
            "Iteration =  529\n",
            "Iteration =  530\n",
            "Iteration =  531\n",
            "Iteration =  532\n",
            "Iteration =  533\n",
            "Iteration =  534\n",
            "Iteration =  535\n",
            "Iteration =  536\n",
            "Iteration =  537\n",
            "Iteration =  538\n",
            "Iteration =  539\n",
            "Iteration =  540\n",
            "Iteration =  541\n",
            "Iteration =  542\n",
            "Iteration =  543\n",
            "Iteration =  544\n",
            "Iteration =  545\n",
            "Iteration =  546\n",
            "Iteration =  547\n",
            "Iteration =  548\n",
            "Iteration =  549\n",
            "Iteration =  550\n",
            "Iteration =  551\n",
            "Iteration =  552\n",
            "Iteration =  553\n",
            "Iteration =  554\n",
            "Iteration =  555\n",
            "Iteration =  556\n",
            "Iteration =  557\n",
            "Iteration =  558\n",
            "Iteration =  559\n",
            "Iteration =  560\n",
            "Iteration =  561\n",
            "Iteration =  562\n",
            "Iteration =  563\n",
            "Iteration =  564\n",
            "Iteration =  565\n",
            "Iteration =  566\n",
            "Iteration =  567\n",
            "Iteration =  568\n",
            "Iteration =  569\n",
            "Iteration =  570\n",
            "Iteration =  571\n",
            "Iteration =  572\n",
            "Iteration =  573\n",
            "Iteration =  574\n",
            "Iteration =  575\n",
            "Iteration =  576\n",
            "Iteration =  577\n",
            "Iteration =  578\n",
            "Iteration =  579\n",
            "Iteration =  580\n",
            "Iteration =  581\n",
            "Iteration =  582\n",
            "Iteration =  583\n",
            "Iteration =  584\n",
            "Iteration =  585\n",
            "Iteration =  586\n",
            "Iteration =  587\n",
            "Iteration =  588\n",
            "Iteration =  589\n",
            "Iteration =  590\n",
            "Iteration =  591\n",
            "Iteration =  592\n",
            "Iteration =  593\n",
            "Iteration =  594\n",
            "Iteration =  595\n",
            "Iteration =  596\n",
            "Iteration =  597\n",
            "Iteration =  598\n",
            "Iteration =  599\n",
            "Iteration =  600\n",
            "step 600: train loss 1.9701, val loss 2.1880\n",
            "Iteration =  601\n",
            "Iteration =  602\n",
            "Iteration =  603\n",
            "Iteration =  604\n",
            "Iteration =  605\n",
            "Iteration =  606\n",
            "Iteration =  607\n",
            "Iteration =  608\n",
            "Iteration =  609\n",
            "Iteration =  610\n",
            "Iteration =  611\n",
            "Iteration =  612\n",
            "Iteration =  613\n",
            "Iteration =  614\n",
            "Iteration =  615\n",
            "Iteration =  616\n",
            "Iteration =  617\n",
            "Iteration =  618\n",
            "Iteration =  619\n",
            "Iteration =  620\n",
            "Iteration =  621\n",
            "Iteration =  622\n",
            "Iteration =  623\n",
            "Iteration =  624\n",
            "Iteration =  625\n",
            "Iteration =  626\n",
            "Iteration =  627\n",
            "Iteration =  628\n",
            "Iteration =  629\n",
            "Iteration =  630\n",
            "Iteration =  631\n",
            "Iteration =  632\n",
            "Iteration =  633\n",
            "Iteration =  634\n",
            "Iteration =  635\n",
            "Iteration =  636\n",
            "Iteration =  637\n",
            "Iteration =  638\n",
            "Iteration =  639\n",
            "Iteration =  640\n",
            "Iteration =  641\n",
            "Iteration =  642\n",
            "Iteration =  643\n",
            "Iteration =  644\n",
            "Iteration =  645\n",
            "Iteration =  646\n",
            "Iteration =  647\n",
            "Iteration =  648\n",
            "Iteration =  649\n",
            "Iteration =  650\n",
            "Iteration =  651\n",
            "Iteration =  652\n",
            "Iteration =  653\n",
            "Iteration =  654\n",
            "Iteration =  655\n",
            "Iteration =  656\n",
            "Iteration =  657\n",
            "Iteration =  658\n",
            "Iteration =  659\n",
            "Iteration =  660\n",
            "Iteration =  661\n",
            "Iteration =  662\n",
            "Iteration =  663\n",
            "Iteration =  664\n",
            "Iteration =  665\n",
            "Iteration =  666\n",
            "Iteration =  667\n",
            "Iteration =  668\n",
            "Iteration =  669\n",
            "Iteration =  670\n",
            "Iteration =  671\n",
            "Iteration =  672\n",
            "Iteration =  673\n",
            "Iteration =  674\n",
            "Iteration =  675\n",
            "Iteration =  676\n",
            "Iteration =  677\n",
            "Iteration =  678\n",
            "Iteration =  679\n",
            "Iteration =  680\n",
            "Iteration =  681\n",
            "Iteration =  682\n",
            "Iteration =  683\n",
            "Iteration =  684\n",
            "Iteration =  685\n",
            "Iteration =  686\n",
            "Iteration =  687\n",
            "Iteration =  688\n",
            "Iteration =  689\n",
            "Iteration =  690\n",
            "Iteration =  691\n",
            "Iteration =  692\n",
            "Iteration =  693\n",
            "Iteration =  694\n",
            "Iteration =  695\n",
            "Iteration =  696\n",
            "Iteration =  697\n",
            "Iteration =  698\n",
            "Iteration =  699\n",
            "Iteration =  700\n",
            "step 700: train loss 1.9615, val loss 2.1071\n",
            "Iteration =  701\n",
            "Iteration =  702\n",
            "Iteration =  703\n",
            "Iteration =  704\n",
            "Iteration =  705\n",
            "Iteration =  706\n",
            "Iteration =  707\n",
            "Iteration =  708\n",
            "Iteration =  709\n",
            "Iteration =  710\n",
            "Iteration =  711\n",
            "Iteration =  712\n",
            "Iteration =  713\n",
            "Iteration =  714\n",
            "Iteration =  715\n",
            "Iteration =  716\n",
            "Iteration =  717\n",
            "Iteration =  718\n",
            "Iteration =  719\n",
            "Iteration =  720\n",
            "Iteration =  721\n",
            "Iteration =  722\n",
            "Iteration =  723\n",
            "Iteration =  724\n",
            "Iteration =  725\n",
            "Iteration =  726\n",
            "Iteration =  727\n",
            "Iteration =  728\n",
            "Iteration =  729\n",
            "Iteration =  730\n",
            "Iteration =  731\n",
            "Iteration =  732\n",
            "Iteration =  733\n",
            "Iteration =  734\n",
            "Iteration =  735\n",
            "Iteration =  736\n",
            "Iteration =  737\n",
            "Iteration =  738\n",
            "Iteration =  739\n",
            "Iteration =  740\n",
            "Iteration =  741\n",
            "Iteration =  742\n",
            "Iteration =  743\n",
            "Iteration =  744\n",
            "Iteration =  745\n",
            "Iteration =  746\n",
            "Iteration =  747\n",
            "Iteration =  748\n",
            "Iteration =  749\n",
            "Iteration =  750\n",
            "Iteration =  751\n",
            "Iteration =  752\n",
            "Iteration =  753\n",
            "Iteration =  754\n",
            "Iteration =  755\n",
            "Iteration =  756\n",
            "Iteration =  757\n",
            "Iteration =  758\n",
            "Iteration =  759\n",
            "Iteration =  760\n",
            "Iteration =  761\n",
            "Iteration =  762\n",
            "Iteration =  763\n",
            "Iteration =  764\n",
            "Iteration =  765\n",
            "Iteration =  766\n",
            "Iteration =  767\n",
            "Iteration =  768\n",
            "Iteration =  769\n",
            "Iteration =  770\n",
            "Iteration =  771\n",
            "Iteration =  772\n",
            "Iteration =  773\n",
            "Iteration =  774\n",
            "Iteration =  775\n",
            "Iteration =  776\n",
            "Iteration =  777\n",
            "Iteration =  778\n",
            "Iteration =  779\n",
            "Iteration =  780\n",
            "Iteration =  781\n",
            "Iteration =  782\n",
            "Iteration =  783\n",
            "Iteration =  784\n",
            "Iteration =  785\n",
            "Iteration =  786\n",
            "Iteration =  787\n",
            "Iteration =  788\n",
            "Iteration =  789\n",
            "Iteration =  790\n",
            "Iteration =  791\n",
            "Iteration =  792\n",
            "Iteration =  793\n",
            "Iteration =  794\n",
            "Iteration =  795\n",
            "Iteration =  796\n",
            "Iteration =  797\n",
            "Iteration =  798\n",
            "Iteration =  799\n",
            "Iteration =  800\n",
            "step 800: train loss 1.8744, val loss 2.0467\n",
            "Iteration =  801\n",
            "Iteration =  802\n",
            "Iteration =  803\n",
            "Iteration =  804\n",
            "Iteration =  805\n",
            "Iteration =  806\n",
            "Iteration =  807\n",
            "Iteration =  808\n",
            "Iteration =  809\n",
            "Iteration =  810\n",
            "Iteration =  811\n",
            "Iteration =  812\n",
            "Iteration =  813\n",
            "Iteration =  814\n",
            "Iteration =  815\n",
            "Iteration =  816\n",
            "Iteration =  817\n",
            "Iteration =  818\n",
            "Iteration =  819\n",
            "Iteration =  820\n",
            "Iteration =  821\n",
            "Iteration =  822\n",
            "Iteration =  823\n",
            "Iteration =  824\n",
            "Iteration =  825\n",
            "Iteration =  826\n",
            "Iteration =  827\n",
            "Iteration =  828\n",
            "Iteration =  829\n",
            "Iteration =  830\n",
            "Iteration =  831\n",
            "Iteration =  832\n",
            "Iteration =  833\n",
            "Iteration =  834\n",
            "Iteration =  835\n",
            "Iteration =  836\n",
            "Iteration =  837\n",
            "Iteration =  838\n",
            "Iteration =  839\n",
            "Iteration =  840\n",
            "Iteration =  841\n",
            "Iteration =  842\n",
            "Iteration =  843\n",
            "Iteration =  844\n",
            "Iteration =  845\n",
            "Iteration =  846\n",
            "Iteration =  847\n",
            "Iteration =  848\n",
            "Iteration =  849\n",
            "Iteration =  850\n",
            "Iteration =  851\n",
            "Iteration =  852\n",
            "Iteration =  853\n",
            "Iteration =  854\n",
            "Iteration =  855\n",
            "Iteration =  856\n",
            "Iteration =  857\n",
            "Iteration =  858\n",
            "Iteration =  859\n",
            "Iteration =  860\n",
            "Iteration =  861\n",
            "Iteration =  862\n",
            "Iteration =  863\n",
            "Iteration =  864\n",
            "Iteration =  865\n",
            "Iteration =  866\n",
            "Iteration =  867\n",
            "Iteration =  868\n",
            "Iteration =  869\n",
            "Iteration =  870\n",
            "Iteration =  871\n",
            "Iteration =  872\n",
            "Iteration =  873\n",
            "Iteration =  874\n",
            "Iteration =  875\n",
            "Iteration =  876\n",
            "Iteration =  877\n",
            "Iteration =  878\n",
            "Iteration =  879\n",
            "Iteration =  880\n",
            "Iteration =  881\n",
            "Iteration =  882\n",
            "Iteration =  883\n",
            "Iteration =  884\n",
            "Iteration =  885\n",
            "Iteration =  886\n",
            "Iteration =  887\n",
            "Iteration =  888\n",
            "Iteration =  889\n",
            "Iteration =  890\n",
            "Iteration =  891\n",
            "Iteration =  892\n",
            "Iteration =  893\n",
            "Iteration =  894\n",
            "Iteration =  895\n",
            "Iteration =  896\n",
            "Iteration =  897\n",
            "Iteration =  898\n",
            "Iteration =  899\n",
            "Iteration =  900\n",
            "step 900: train loss 1.8573, val loss 2.0337\n",
            "Iteration =  901\n",
            "Iteration =  902\n",
            "Iteration =  903\n",
            "Iteration =  904\n",
            "Iteration =  905\n",
            "Iteration =  906\n",
            "Iteration =  907\n",
            "Iteration =  908\n",
            "Iteration =  909\n",
            "Iteration =  910\n",
            "Iteration =  911\n",
            "Iteration =  912\n",
            "Iteration =  913\n",
            "Iteration =  914\n",
            "Iteration =  915\n",
            "Iteration =  916\n",
            "Iteration =  917\n",
            "Iteration =  918\n",
            "Iteration =  919\n",
            "Iteration =  920\n",
            "Iteration =  921\n",
            "Iteration =  922\n",
            "Iteration =  923\n",
            "Iteration =  924\n",
            "Iteration =  925\n",
            "Iteration =  926\n",
            "Iteration =  927\n",
            "Iteration =  928\n",
            "Iteration =  929\n",
            "Iteration =  930\n",
            "Iteration =  931\n",
            "Iteration =  932\n",
            "Iteration =  933\n",
            "Iteration =  934\n",
            "Iteration =  935\n",
            "Iteration =  936\n",
            "Iteration =  937\n",
            "Iteration =  938\n",
            "Iteration =  939\n",
            "Iteration =  940\n",
            "Iteration =  941\n",
            "Iteration =  942\n",
            "Iteration =  943\n",
            "Iteration =  944\n",
            "Iteration =  945\n",
            "Iteration =  946\n",
            "Iteration =  947\n",
            "Iteration =  948\n",
            "Iteration =  949\n",
            "Iteration =  950\n",
            "Iteration =  951\n",
            "Iteration =  952\n",
            "Iteration =  953\n",
            "Iteration =  954\n",
            "Iteration =  955\n",
            "Iteration =  956\n",
            "Iteration =  957\n",
            "Iteration =  958\n",
            "Iteration =  959\n",
            "Iteration =  960\n",
            "Iteration =  961\n",
            "Iteration =  962\n",
            "Iteration =  963\n",
            "Iteration =  964\n",
            "Iteration =  965\n",
            "Iteration =  966\n",
            "Iteration =  967\n",
            "Iteration =  968\n",
            "Iteration =  969\n",
            "Iteration =  970\n",
            "Iteration =  971\n",
            "Iteration =  972\n",
            "Iteration =  973\n",
            "Iteration =  974\n",
            "Iteration =  975\n",
            "Iteration =  976\n",
            "Iteration =  977\n",
            "Iteration =  978\n",
            "Iteration =  979\n",
            "Iteration =  980\n",
            "Iteration =  981\n",
            "Iteration =  982\n",
            "Iteration =  983\n",
            "Iteration =  984\n",
            "Iteration =  985\n",
            "Iteration =  986\n",
            "Iteration =  987\n",
            "Iteration =  988\n",
            "Iteration =  989\n",
            "Iteration =  990\n",
            "Iteration =  991\n",
            "Iteration =  992\n",
            "Iteration =  993\n",
            "Iteration =  994\n",
            "Iteration =  995\n",
            "Iteration =  996\n",
            "Iteration =  997\n",
            "Iteration =  998\n",
            "Iteration =  999\n",
            "step 999: train loss 1.7889, val loss 2.0177\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "  model = NanoGPT()\n",
        "\n",
        "  optimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate)\n",
        "\n",
        "  for iter in range(max_iters):\n",
        "    print(\"Iteration = \", iter)\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "      losses = lossObj.estimate_loss()\n",
        "      print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = dataObj.get_batch('train')\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        _, loss = model(xb, yb)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generateNext()"
      ],
      "metadata": {
        "id": "fjjvMifYZf7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3156ed5a-56ec-46dc-ab14-9599f5538521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "se\n",
            "\n",
            "\n",
            "kt\n",
            "\"Tm\n",
            ",p\"8    tylmea,e,   pySapncceelw .  aIoMyeiefs  rteo i miiaenntno aintvveeeet,lry a \n",
            "lractgdi t yy\n",
            "evvvvieee,css a  teyurnrinnntsh  thtantiteiaislnn.,ggoi ofvffeueellrlsysyt.  ySy\"TT fhkuelr raeeetdrlyeey. w. \"  dmyatnsrooaens,d e  obeb-euonirryy eveaveeie,n saaaonrnnd  evUvmeeae,slyan saiaed sdeeo wtfkie.inwn9.   \n",
            "liBeReed rn out eievvasuo istlbeeeinnnn e greoeydn tasy   evwGacliteiiecsvnss slSotee  ay\n",
            "cahah  ngeoia ntgeeee, .lioo:    wbi\"IITJeeA \n",
            "SSSOIOANR LAHEO RYREIOalrrl a edjnfoo ofrffueiatltru a aaltiihraeis  eexc%xei liouinvCveiees  liaeasrwtc e aiatuuei vnzoeeanlrleaiacnslyyie s sooee'r sacchieteen stuae dns ei tmwfueievndd.  .    aaraiptceoiovnnugga'ttttirialdll aey  t eitamkrinner ,yinknnset'srns    p'wannrsnaeeps. Y\n",
            "IT    aawwa ae—d  ylwken eaavaisylyyyi,nnnee chreAnctneieenvvnoy ,    a\n",
            "\n",
            "yoooo   seaoef sdooiinntni os  eimmmniooouss oaycheehi,.t ' yoooocuuustss i  y\n",
            "pdaeeopnnpeyeinnnn    bdtreoeenslrs,elyys i\n",
            "e\n",
            "1&\n",
            "S    sKPwoiiar\n",
            "t1 2n tM\n",
            "JAOtEr   Utelitfte,ees,rlyee otcooun sRateihe s setcensaeo r fyot' h actleiyast taohhiiionnnnz':e r  \n",
            "\n",
            "Steeoe.r thhhouuuugggghhhhe  thooh ee \n",
            "sdhoaee ns aats    aase,a  k\n",
            "Hfewealtrg ieepspveeeen., \n",
            "H\n",
            "owwwulsialllly  ofrbfowoolmrnniyielnngag'tttayrilili Aslreoainnrn.ise rd,    aafalyrylii ohfinnem,   clihneeairrl  ienvvmoii:   11'ssttitiaeusl'.    thtamymiencni is  ecorrroeaincvviiees,v,    y1pthhhhieiifnnncggg ie,    buy8   \"STTYoooe    taJbeaee  , S\n",
            "acVhkhoe-.    yce\"LfDt    oIaatrsceeie  s wto\n",
            "\n",
            "F\n",
            "\n",
            "\"S/\n",
            "YD1\n",
            "27 0681839”\"91W992  \n",
            "W\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ABE3ER  ARAHROR Rnoe offnrs, emfantttdiieessds  ., \"  w\n",
            "yisdsst   bywyl -iggtdieaalit ahom,l. TT\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "l\n",
            "\n",
            "Y¢e1 16« 0: WIIS  \" B\n",
            "\n",
            "jouuustrs   aswpraooaliblooiacrll ieivvnioefn   ceiaJeeei,nn'titthhiy- ,! b  at\"doieonnnno'ey  s blmatgcmisiicnsceeye dd cataunnulitceiiesvvn,e. YJ\n",
            "Preeinnnnectioooo,nnn 'e'rorleey \n",
            "htayrs,    hjytoohhiiiisnnnog''tttde.erei ,    \n",
            "tktahrinnct eialill eyeaixrge eannxtiiteiiinsrn'ge ftiounundccdei evavveeoe dss,to.  , atHrroaeg! scaoonk neooonsu djlattir\n"
          ]
        }
      ]
    }
  ]
}